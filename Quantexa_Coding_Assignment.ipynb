{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf19d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.0.113:4040\n",
       "SparkContext available as 'sc' (version = 3.1.1, master = local[*], app id = local-1621948633552)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark._\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.sql.expressions.Window\n",
       "import org.apache.spark.sql.SparkSession\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdc7a3f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flightDF: org.apache.spark.sql.DataFrame = [passengerId: int, flightId: int ... 3 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Load flightData.csv into dataframe\n",
    "val flightDF = spark.read.format(\"csv\")\n",
    ".option(\"header\", \"true\")\n",
    ".option(\"inferSchema\", \"true\")\n",
    ".load(\"./flightData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84882230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passengerId: integer (nullable = true)\n",
      " |-- flightId: integer (nullable = true)\n",
      " |-- from: string (nullable = true)\n",
      " |-- to: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Check if schema is properly ingested according to the defined schema\n",
    "flightDF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc564b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Array[org.apache.spark.sql.Row] = Array([12704,999,co,cg,2017-12-31], [12078,999,co,cg,2017-12-31], [14582,999,co,cg,2017-12-31], [2689,999,co,cg,2017-12-31], [2244,999,co,cg,2017-12-31], [14100,999,co,cg,2017-12-31], [9397,999,co,cg,2017-12-31], [7682,999,co,cg,2017-12-31], [12429,999,co,cg,2017-12-31], [9217,999,co,cg,2017-12-31])\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//display top/bottom 10 records from flightDF to check the data ingested\n",
    "flightDF.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c65b7c",
   "metadata": {},
   "source": [
    "Question 1 - Find the total number of flights for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb18de81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlightsPerMonth: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Month: int, Number of Flights: bigint]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Extract month from the date field and name the field as month, and get distinct count of flightId grouped by month\n",
    "\n",
    "val FlightsPerMonth = flightDF.withColumn(\"Month\", month(to_date($\"date\"))).groupBy($\"Month\")\n",
    "    .agg(countDistinct($\"flightId\").alias(\"Number of Flights\"))\n",
    "    .orderBy($\"Month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8427552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|Month|Number of Flights|\n",
      "+-----+-----------------+\n",
      "|    1|               97|\n",
      "|    2|               73|\n",
      "|    3|               82|\n",
      "|    4|               92|\n",
      "|    5|               92|\n",
      "|    6|               71|\n",
      "|    7|               87|\n",
      "|    8|               76|\n",
      "|    9|               85|\n",
      "|   10|               76|\n",
      "|   11|               75|\n",
      "|   12|               94|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Dispaly the result to check if the business logic is correctly implemented on the flightDF\n",
    "FlightsPerMonth.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a578db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "//Export the result as csv\n",
    "FlightsPerMonth.coalesce(1)//to create one partition\n",
    "      .write\n",
    "      .option(\"header\",\"true\")\n",
    "      .option(\"sep\",\",\")\n",
    "      .mode(\"overwrite\")\n",
    "      .csv(\"./Flights Per Month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f842eb",
   "metadata": {},
   "source": [
    "Question 2 - Find the names of the 100 most frequent flyers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cf5d81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passengerDF: org.apache.spark.sql.DataFrame = [passengerId: int, firstName: string ... 1 more field]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Load passengers.csv into dataframe\n",
    "\n",
    "val passengerDF = spark.read.format(\"csv\")\n",
    ".option(\"header\", \"true\")\n",
    ".option(\"inferSchema\", \"true\")\n",
    ".load(\"./passengers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d53d461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passengerId: integer (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Check the schema\n",
    "passengerDF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ba0bdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+--------+\n",
      "|passengerId|firstName|lastName|\n",
      "+-----------+---------+--------+\n",
      "|      14751| Napoleon| Gaylene|\n",
      "|       2359| Katherin| Shanell|\n",
      "|       5872|   Stevie|  Steven|\n",
      "|       3346|Margarita|   Gerri|\n",
      "|       3704|    Earle|  Candis|\n",
      "|       1226|    Trent|    Omer|\n",
      "|       2677|    Janee|  Lillia|\n",
      "|        179|     Gita|Chastity|\n",
      "|       9763|   Hilton|Jaquelyn|\n",
      "|      11414|      Leo|Margaret|\n",
      "|       6870|     Tama|     Bok|\n",
      "|       3290|    Logan|    Anya|\n",
      "|      13264|   Lowell|Kathryne|\n",
      "|        455|  Maritza|  Maxima|\n",
      "|      13006|     Yuri|   Joyce|\n",
      "|      10323|  Latasha|  Estell|\n",
      "|       7376|   Kaycee|Kiersten|\n",
      "|      15015|   Curtis| Abraham|\n",
      "|       9217|   Verena|Josefine|\n",
      "|       5183|     Loan| Latonya|\n",
      "+-----------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//display top/bottom 20 records to check the data ingested\n",
    "\n",
    "passengerDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b78a0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frequentFlyersDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Passenger ID: int, First name: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Count the flights for each passengers in descending order\n",
    "\n",
    "val frequentFlyersDF = flightDF\n",
    "  .join(passengerDF, flightDF(\"passengerId\") ===  passengerDF(\"passengerId\"),\"inner\")\n",
    "  .groupBy(flightDF(\"passengerId\").as(\"Passenger ID\"), $\"firstName\".as(\"First name\"), $\"lastName\".as(\"Last name\"))\n",
    "  .agg(count($\"flightId\")\n",
    "  .as(\"Number of Flights\")).orderBy($\"Number of Flights\".desc).limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f622bad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+---------+-----------------+\n",
      "|Passenger ID|First name|Last name|Number of Flights|\n",
      "+------------+----------+---------+-----------------+\n",
      "|        2068|   Yolande|     Pete|               32|\n",
      "|        1677| Katherina| Vasiliki|               27|\n",
      "|        4827|     Jaime|    Renay|               27|\n",
      "|        3173|  Sunshine|    Scott|               26|\n",
      "|        8961|     Ginny|    Clara|               26|\n",
      "|         288|    Pamila|    Mavis|               25|\n",
      "|         917|    Anisha|   Alaine|               25|\n",
      "|        5096|    Blythe|     Hyon|               25|\n",
      "|         760|    Vernia|      Mui|               25|\n",
      "|        6084|      Cole|   Sharyl|               25|\n",
      "|        8363|    Branda|   Kimiko|               25|\n",
      "|        5867|     Luise|  Raymond|               25|\n",
      "|        2857|       Son|  Ginette|               25|\n",
      "|        3367| Priscilla|    Corie|               24|\n",
      "|        1343|   Bennett|    Staci|               24|\n",
      "|        1240| Catherine|    Missy|               24|\n",
      "|        2441|     Kayla|    Rufus|               24|\n",
      "|        5668|    Gladis|  Earlene|               24|\n",
      "|        3405|     Johna|    Ollie|               23|\n",
      "|        8353|     Davis| Williams|               23|\n",
      "+------------+----------+---------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Show the top 20 frequent flyers to check if the logic has been implemented properly\n",
    "\n",
    "frequentFlyersDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2744d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "//Export the result as csv\n",
    "frequentFlyersDF.coalesce(1)//to create one partition\n",
    "      .write\n",
    "      .option(\"header\",\"true\")\n",
    "      .option(\"sep\",\",\")\n",
    "      .mode(\"overwrite\")\n",
    "      .csv(\"./Top 100 Frequent Flyers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f140db1",
   "metadata": {},
   "source": [
    "Question 3 - Find the greatest number of countries a passenger has been in without being in the UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ded6fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "w: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@565c7d8f\n",
       "lastFlightDF: org.apache.spark.sql.DataFrame = [passengerId: int, flightId: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Get the last flight for each passenger to be unioned with the original flight dataframe\n",
    "\n",
    "val w = Window.partitionBy($\"passengerId\")\n",
    "\n",
    "val lastFlightDF = flightDF.withColumn(\"seq\", row_number().over(w.orderBy($\"date\".desc)))\n",
    "  .filter($\"seq\" === \"1\").drop(\"seq\",\"from\").withColumnRenamed(\"to\", \"itinerary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dc7541f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itineraryDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [passengerId: int, flightId: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Append the last \"to\" country to \"from\" countries for each passenger with a renamed column \"itinerary\"\n",
    "\n",
    "val itineraryDF = flightDF\n",
    "    .drop(\"to\")\n",
    "    .withColumnRenamed(\"from\", \"itinerary\")\n",
    "    .union(lastFlightDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebe4c2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itineraryArrayDF: org.apache.spark.sql.DataFrame = [passengerId: int, itinerary: array<string>]\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Convert the itinerary into a single array for each passenger \n",
    "\n",
    "val itineraryArrayDF = itineraryDF\n",
    "  .groupBy(\"passengerId\")\n",
    "  .agg(collect_list(\"itinerary\") as \"itinerary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56075f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longestRunUDF: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda$4419/571972504@775e7bda,IntegerType,List(Some(class[value[0]: array<string>])),Some(class[value[0]: int]),None,false,true)\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Create a udf that will split each array of itinerary by uk and get the max number of the splitted arrays of the\n",
    "//distinct countires \n",
    "\n",
    "val longestRunUDF = udf((ar: Array[String]) => ar.mkString(\" \")\n",
    "      .split(\"uk\") \n",
    "      .filter(_.nonEmpty)\n",
    "      .map(_.trim)\n",
    "      .map(s => s.split(\" \").distinct.length)\n",
    "      .max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "219eb08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longestRunDF: org.apache.spark.sql.DataFrame = [passengerId: int, Longest Run: int]\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Call the udf on the itineraryArrayDF\n",
    "val longestRunDF = itineraryArrayDF.withColumn(\"Longest Run\", longestRunUDF($\"itinerary\")).drop($\"itinerary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33c7592f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|passengerId|Longest Run|\n",
      "+-----------+-----------+\n",
      "|       9441|         19|\n",
      "|        288|         19|\n",
      "|       3608|         18|\n",
      "|       2437|         18|\n",
      "|       2867|         18|\n",
      "|       2068|         18|\n",
      "|       3117|         17|\n",
      "|        888|         17|\n",
      "|       3309|         17|\n",
      "|       2378|         17|\n",
      "|        798|         17|\n",
      "|       1337|         17|\n",
      "|       5668|         17|\n",
      "|       1651|         17|\n",
      "|       1074|         17|\n",
      "|         92|         17|\n",
      "|        950|         17|\n",
      "|       2857|         17|\n",
      "|       3173|         17|\n",
      "|        525|         17|\n",
      "+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Disply the top 20 result and compare it with the orginal flight csv file for testing\n",
    "longestRunDF.orderBy($\"Longest Run\".desc).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfad528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "//Export the result as csv\n",
    "longestRunDF.coalesce(1)//to create one partition\n",
    "      .write\n",
    "      .option(\"header\",\"true\")\n",
    "      .option(\"sep\",\",\")\n",
    "      .mode(\"overwrite\")\n",
    "      .csv(\"./Longest Run Per Passenger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0e36d4",
   "metadata": {},
   "source": [
    "Question 4 - Find the passengers who have been on more than 3 flights together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dce91e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flightTogetherDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Passenger 1 ID: int, Passenger 2 ID: int ... 1 more field]\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Count the flights grouped by the passengers who are on the same flight & on the same date where the number of\n",
    "// flights > 3\n",
    "\n",
    "val flightTogetherDF = flightDF.as(\"df1\").join(flightDF.as(\"df2\"),\n",
    "    $\"df1.passengerId\" < $\"df2.passengerId\" &&\n",
    "    $\"df1.flightId\" === $\"df2.flightId\" &&\n",
    "    $\"df1.date\" === $\"df2.date\",\n",
    "    \"inner\"\n",
    "  ).\n",
    "  groupBy($\"df1.passengerId\".as(\"Passenger 1 ID\"), $\"df2.passengerId\".as(\"Passenger 2 ID\")).\n",
    "  agg(count(\"*\").as(\"Number of flights together\")).\n",
    "  where($\"Number of flights together\" >= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8499e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------------+\n",
      "|Passenger 1 ID|Passenger 2 ID|Number of flights together|\n",
      "+--------------+--------------+--------------------------+\n",
      "|           701|           760|                        15|\n",
      "|          2717|          2759|                        14|\n",
      "|          3503|          3590|                        14|\n",
      "|          2939|          5490|                        13|\n",
      "|          3278|          5423|                        12|\n",
      "|          2550|          4441|                        12|\n",
      "|           382|           392|                        12|\n",
      "|           760|           763|                        12|\n",
      "|          4316|          4373|                        12|\n",
      "|          3021|          9522|                        12|\n",
      "|           975|          1371|                        12|\n",
      "|          2759|          4316|                        12|\n",
      "|           366|           374|                        12|\n",
      "|          4395|          4399|                        12|\n",
      "|          2939|          4395|                        12|\n",
      "|          1337|          1484|                        12|\n",
      "|          1337|          2867|                        12|\n",
      "|          2926|          3590|                        12|\n",
      "|           701|           763|                        12|\n",
      "|          1208|          3093|                        12|\n",
      "+--------------+--------------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// disply the top 20 results to compare it with the orginal flight csv for testing\n",
    "flightTogetherDF.orderBy($\"Number of flights together\".desc)show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d96d5e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "//Export the result as csv\n",
    "flightTogetherDF.coalesce(1)//to create one partition\n",
    "      .write\n",
    "      .option(\"header\",\"true\")\n",
    "      .option(\"sep\",\",\")\n",
    "      .mode(\"overwrite\")\n",
    "      .csv(\"./More than Three Flights Together\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f07596dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import java.text.SimpleDateFormat\n",
       "import java.util.Date\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.text.SimpleDateFormat\n",
    "import java.util.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5196483e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flownTogether: (atLeastNTimes: Int, from: java.util.Date, to: java.util.Date)Unit\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Create function that return the passengers who have been on more than N flights together within the range (from,to)\n",
    "//Save the reult to a csv file\n",
    "\n",
    "def flownTogether(atLeastNTimes: Int, from: Date, to: Date) = {\n",
    "  val flightNTogetherDF = flightDF.as(\"df1\").join(flightDF.as(\"df2\"),\n",
    "    $\"df1.passengerId\" < $\"df2.passengerId\" &&\n",
    "    $\"df1.flightId\" === $\"df2.flightId\" &&\n",
    "    $\"df1.date\" === $\"df2.date\" &&\n",
    "    $\"df1.date\" >= from &&\n",
    "    $\"df1.date\" <= to,\n",
    "    \"inner\"\n",
    "  ).\n",
    "  groupBy($\"df1.passengerId\".as(\"Passenger 1 ID\"), $\"df2.passengerId\".as(\"Passenger 2 ID\")).\n",
    "  agg(count(\"*\").as(\"Number of flights together\"), min($\"df1.date\").as(\"from\"), max($\"df1.date\").as(\"to\")).\n",
    "  where($\"Number of flights together\" >= atLeastNTimes) \n",
    "  \n",
    "   flightNTogetherDF.coalesce(1)//to create one partition\n",
    "      .write\n",
    "      .option(\"header\",\"true\")\n",
    "      .option(\"sep\",\",\")\n",
    "      .mode(\"overwrite\")\n",
    "      .csv(\"./Flight N Together\")\n",
    "    \n",
    "    println(\"The Flight N Together result has been saved as csv\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2618ca4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined object Utils\n",
       "convertDateStringToLong: (dateAsString: String)Long\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Create a function to generate from and to date to test the function flownTogether\n",
    "\n",
    "object Utils {\n",
    "\n",
    "    val DATE_FORMAT = \"yyyy-MMM-dd\"\n",
    "\n",
    "    def convertStringToDate(s: String): Date = {\n",
    "        val dateFormat = new SimpleDateFormat(DATE_FORMAT)\n",
    "        dateFormat.parse(s)\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "def convertDateStringToLong(dateAsString: String): Long = {\n",
    "    Utils.convertStringToDate(dateAsString).getTime\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b257fb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Flight N Together result has been saved as csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "from: java.sql.Date = 2017-12-18\n",
       "to: java.sql.Date = 2017-12-28\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Testing the function flownTogether and compare the result to the orginal flightData.csv to check the logic\n",
    "val from = new java.sql.Date(convertDateStringToLong(\"2017-Dec-18\"))\n",
    "val to = new java.sql.Date(convertDateStringToLong(\"2017-Dec-28\"))\n",
    "\n",
    "flownTogether(2, from, to)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
